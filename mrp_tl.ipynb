{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ScaAB4S3vBVp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ScaAB4S3vBVp",
    "outputId": "5e328fe0-0882-45c5-b724-0f959606fcf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting deeplabcut[modelzoo,tf]\n",
      "  Downloading deeplabcut-2.3.5-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorpack>=0.11\n",
      "  Downloading tensorpack-0.11-py2.py3-none-any.whl (296 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.3/296.3 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tables>=3.7.0 in /uoa/home/t08io22/.local/lib/python3.9/site-packages (from deeplabcut[modelzoo,tf]) (3.8.0)\n",
      "Collecting filterpy>=1.4.4\n",
      "  Downloading filterpy-1.4.5.zip (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scikit-image>=0.17\n",
      "  Downloading scikit_image-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tf-slim>=1.1.0\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dlclibrary\n",
      "  Downloading dlclibrary-0.0.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: tqdm in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from deeplabcut[modelzoo,tf]) (4.64.0)\n",
      "Collecting imgaug>=0.4.0\n",
      "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.0/948.0 KB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn>=1.0\n",
      "  Downloading scikit_learn-1.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting imageio-ffmpeg\n",
      "  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numba>=0.54 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from deeplabcut[modelzoo,tf]) (0.55.2)\n",
      "Collecting torch<=1.12\n",
      "  Downloading torch-1.12.0-cp39-cp39-manylinux1_x86_64.whl (776.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting ruamel.yaml>=0.15.0\n",
      "  Downloading ruamel.yaml-0.17.31-py3-none-any.whl (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.1/112.1 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting statsmodels>=0.11\n",
      "  Downloading statsmodels-0.14.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from deeplabcut[modelzoo,tf]) (1.22.4)\n",
      "Requirement already satisfied: Pillow>=7.1 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from deeplabcut[modelzoo,tf]) (9.1.1)\n",
      "Requirement already satisfied: pandas!=1.5.0,>=1.0.1 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from deeplabcut[modelzoo,tf]) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.4 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from deeplabcut[modelzoo,tf]) (1.8.1)\n",
      "Requirement already satisfied: networkx>=2.6 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from deeplabcut[modelzoo,tf]) (2.8.4)\n",
      "Requirement already satisfied: matplotlib>=3.3 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from deeplabcut[modelzoo,tf]) (3.5.2)\n",
      "Requirement already satisfied: pyyaml in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from deeplabcut[modelzoo,tf]) (6.0)\n",
      "Collecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 KB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow<=2.10,>=2.0\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting imageio\n",
      "  Downloading imageio-2.31.0-py3-none-any.whl (313 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Shapely\n",
      "  Downloading shapely-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting opencv-python\n",
      "  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from imgaug>=0.4.0->deeplabcut[modelzoo,tf]) (1.16.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from matplotlib>=3.3->deeplabcut[modelzoo,tf]) (4.33.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from matplotlib>=3.3->deeplabcut[modelzoo,tf]) (1.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from matplotlib>=3.3->deeplabcut[modelzoo,tf]) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from matplotlib>=3.3->deeplabcut[modelzoo,tf]) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from matplotlib>=3.3->deeplabcut[modelzoo,tf]) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from matplotlib>=3.3->deeplabcut[modelzoo,tf]) (21.3)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from numba>=0.54->deeplabcut[modelzoo,tf]) (0.38.1)\n",
      "Requirement already satisfied: setuptools in /opt/software/uoa/spack-sw/linux-rhel8-x86_64/gcc-12.1.0/python-3.9.12-u2o5ndnqcbr26nc573ubjrvv7o5n5wts/lib/python3.9/site-packages (from numba>=0.54->deeplabcut[modelzoo,tf]) (58.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from pandas!=1.5.0,>=1.0.1->deeplabcut[modelzoo,tf]) (2022.1)\n",
      "Collecting ruamel.yaml.clib>=0.2.7\n",
      "  Downloading ruamel.yaml.clib-0.2.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (519 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.4/519.4 KB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lazy_loader>=0.2\n",
      "  Downloading lazy_loader-0.2-py3-none-any.whl (8.6 kB)\n",
      "Collecting tifffile>=2022.8.12\n",
      "  Downloading tifffile-2023.4.12-py3-none-any.whl (219 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.4/219.4 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from scikit-learn>=1.0->deeplabcut[modelzoo,tf]) (3.1.0)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting patsy>=0.5.2\n",
      "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.8/233.8 KB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: py-cpuinfo in /uoa/home/t08io22/.local/lib/python3.9/site-packages (from tables>=3.7.0->deeplabcut[modelzoo,tf]) (9.0.0)\n",
      "Requirement already satisfied: blosc2~=2.0.0 in /uoa/home/t08io22/.local/lib/python3.9/site-packages (from tables>=3.7.0->deeplabcut[modelzoo,tf]) (2.0.0)\n",
      "Requirement already satisfied: cython>=0.29.21 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from tables>=3.7.0->deeplabcut[modelzoo,tf]) (0.29.30)\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /uoa/home/t08io22/.local/lib/python3.9/site-packages (from tables>=3.7.0->deeplabcut[modelzoo,tf]) (2.8.4)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.32.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (1.14.1)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (3.7.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/software/uoa/spack-sw/linux-rhel8-x86_64/gcc-12.1.0/python-3.9.12-u2o5ndnqcbr26nc573ubjrvv7o5n5wts/lib/python3.9/site-packages (from tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (4.4.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (1.1.2)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 KB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (1.1.0)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (1.46.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (14.0.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (0.2.0)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (3.19.4)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (1.6.3)\n",
      "Requirement already satisfied: msgpack>=0.5.2 in /uoa/home/t08io22/.local/lib/python3.9/site-packages (from tensorpack>=0.11->deeplabcut[modelzoo,tf]) (1.0.5)\n",
      "Requirement already satisfied: pyzmq>=16 in /opt/software/uoa/python-pkgs/3.9/jupyter/8.4.0/lib/python3.9/site-packages (from tensorpack>=0.11->deeplabcut[modelzoo,tf]) (23.2.0)\n",
      "Requirement already satisfied: psutil>=5 in /opt/software/uoa/python-pkgs/3.9/jupyter/8.4.0/lib/python3.9/site-packages (from tensorpack>=0.11->deeplabcut[modelzoo,tf]) (5.9.1)\n",
      "Collecting msgpack-numpy>=0.4.4.2\n",
      "  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n",
      "Collecting tabulate>=0.7.7\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: requests in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from huggingface-hub->deeplabcut[modelzoo,tf]) (2.28.0)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from huggingface-hub->deeplabcut[modelzoo,tf]) (3.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (2.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (3.3.7)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (2.1.2)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 KB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from requests->huggingface-hub->deeplabcut[modelzoo,tf]) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from requests->huggingface-hub->deeplabcut[modelzoo,tf]) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from requests->huggingface-hub->deeplabcut[modelzoo,tf]) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from requests->huggingface-hub->deeplabcut[modelzoo,tf]) (3.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[modelzoo,tf]) (3.2.0)\n",
      "Building wheels for collected packages: filterpy\n",
      "  Building wheel for filterpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110474 sha256=493a9ae358fc194b0aa087d66d9f1c2114baae349a5c52d4be2131b543fb93f8\n",
      "  Stored in directory: /uoa/home/t08io22/.cache/pip/wheels/53/e6/de/a09ea01e923aaf88b9f8c7c44329e857b2c1a31901167e55e6\n",
      "Successfully built filterpy\n",
      "Installing collected packages: tensorboard-plugin-wit, keras, flatbuffers, torch, tifffile, tf-slim, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, tabulate, Shapely, ruamel.yaml.clib, PyWavelets, patsy, opencv-python, msgpack-numpy, lazy_loader, joblib, imageio-ffmpeg, imageio, fsspec, tensorpack, scikit-learn, scikit-image, ruamel.yaml, huggingface-hub, statsmodels, imgaug, filterpy, dlclibrary, tensorboard, deeplabcut, tensorflow\n",
      "Successfully installed PyWavelets-1.4.1 Shapely-2.0.1 deeplabcut-2.3.5 dlclibrary-0.0.3 filterpy-1.4.5 flatbuffers-23.5.26 fsspec-2023.5.0 huggingface-hub-0.15.1 imageio-2.31.0 imageio-ffmpeg-0.4.8 imgaug-0.4.0 joblib-1.2.0 keras-2.10.0 lazy_loader-0.2 msgpack-numpy-0.4.8 opencv-python-4.7.0.72 patsy-0.5.3 ruamel.yaml-0.17.31 ruamel.yaml.clib-0.2.7 scikit-image-0.21.0 scikit-learn-1.2.2 statsmodels-0.14.0 tabulate-0.9.0 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.32.0 tensorpack-0.11 tf-slim-1.1.0 tifffile-2023.4.12 torch-1.12.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/opt/software/uoa/spack-sw/linux-rhel8-x86_64/gcc-12.1.0/python-3.9.12-u2o5ndnqcbr26nc573ubjrvv7o5n5wts/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install deeplabcut[tf,modelzoo]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbfb0891",
   "metadata": {
    "id": "dbfb0891"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 10:13:48.950202: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-12 10:13:49.526630: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-12 10:13:54.010813: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/software/uoa/spack-sw/linux-rhel8-x86_64/gcc-12.1.0/libiconv-1.16-o5xic5hftcncnk3zgrajfx6nbjnaenun/lib:/opt/software/uoa/spack-sw/linux-rhel8-x86_64/gcc-12.1.0/r-4.1.3-gixu37cbx7dcnwzya2lu7jimi4qd2gl6/rlib/R/lib:/opt/software/uoa/spack-sw/linux-rhel8-x86_64/gcc-12.1.0/python-3.9.12-u2o5ndnqcbr26nc573ubjrvv7o5n5wts/lib:/opt/slurm/22.05.2-1/lib\n",
      "2023-06-12 10:13:54.012465: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/software/uoa/spack-sw/linux-rhel8-x86_64/gcc-12.1.0/libiconv-1.16-o5xic5hftcncnk3zgrajfx6nbjnaenun/lib:/opt/software/uoa/spack-sw/linux-rhel8-x86_64/gcc-12.1.0/r-4.1.3-gixu37cbx7dcnwzya2lu7jimi4qd2gl6/rlib/R/lib:/opt/software/uoa/spack-sw/linux-rhel8-x86_64/gcc-12.1.0/python-3.9.12-u2o5ndnqcbr26nc573ubjrvv7o5n5wts/lib:/opt/slurm/22.05.2-1/lib\n",
      "2023-06-12 10:13:54.012500: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.5...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut as dlc\n",
    "import tensorflow\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "\n",
    "video_path = Path(os.getcwd() + \"/dummy-video.mp4\")\n",
    "\n",
    "# Ensure video file exists\n",
    "assert video_path.is_file()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2e0cb1",
   "metadata": {
    "id": "5f2e0cb1"
   },
   "source": [
    "Load weights from pre-trained macaque model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68a7680",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549,
     "referenced_widgets": [
      "e1eb9cf9735d486d9387cde84ab171c6",
      "a48d9de30ddf459aa5336875598bbe29",
      "6eb4b916a5474378a25ed3fe14a6b7cf",
      "cbcd3ba6bed1420eb3d944b4e16fd2f3",
      "7375a8cf081949a696e0076c100c4afa",
      "b4b51803fb314a82970dead9a0b39c9f",
      "96d5d8708f6d495dbeea3790037c4afc",
      "d1f1df6732a343789fe6a99f3c8af4b7",
      "ae4402332ffe403b9255be9e0326b268",
      "433bb754a9804b2082279408bcc0b475",
      "c6ca5ecece2443ddad8a8eab539ceef2"
     ]
    },
    "id": "1b72371a",
    "outputId": "1d625a92-9884-4c4b-a841-78a66f5b12df"
   },
   "outputs": [],
   "source": [
    "config_path, train_config_path = dlc.create_pretrained_project(\n",
    "    \"mrp\",\n",
    "    \"scorer\",\n",
    "    [video_path],\n",
    "    videotype=\"mp4\",\n",
    "    model=\"full_macaque\",\n",
    "    analyzevideo=False,         # True: a labeled video is created, else only weights downloaded\n",
    "    createlabeledvideo=True,    # ? no documentation available\n",
    "    copy_videos=True,           # From Colab: must leave copy_videos=True (?)\n",
    ")\n",
    "config_file = dlc.auxiliaryfunctions.read_plainconfig(config_path)\n",
    "# Set iteration to value +1 from init_weights (possibly later than here?)\n",
    "config_file[\"iteration\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000ccfd3",
   "metadata": {
    "id": "873f2961"
   },
   "source": [
    "Use command line functionality to load COCO annotation and image data into required labeled-data sub-directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9230d544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/uoa/scratch/users/t08io22/pommes-test/mrp-scorer-2023-06-09/labeled-data/dummy-video\n"
     ]
    }
   ],
   "source": [
    "today = date.today()\n",
    "data_dir = Path(os.getcwd() + f\"/mrp-scorer-{today}/labeled-data/dummy-video\")\n",
    "print(data_dir)\n",
    "\n",
    "# Load annotations if desired file exists\n",
    "anno_file = Path(\"coco2017_val_subset_anno.h5\")\n",
    "assert anno_file.is_file()\n",
    "!cp {str(anno_file)} {data_dir / \"CollectedData_scorer.h5\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98330eb1",
   "metadata": {},
   "source": [
    "Extract list of files that are actually to copy, and use the list to copy image files into required folder.\n",
    "\n",
    "Load extract indices for train/test from full dataframe that we load here, but manipulate during preprocessing already.\n",
    "\n",
    "(Note: # (If copying the whole folder: !cp ../coco/val2017/* {data_dir}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fa4d20fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '../coco/train2017/000000142620.jpg': No such file or directory\n",
      "cp: cannot stat '../coco/train2017/000000163682.jpg': No such file or directory\n",
      "cp: cannot stat '../coco/train2017/000000209753.jpg': No such file or directory\n",
      "cp: cannot stat '../coco/train2017/000000275058.jpg': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_hdf(data_dir / \"CollectedData_scorer.h5\")\n",
    "\n",
    "# Extract train/test information\n",
    "\n",
    "df_train = df[df[\"istrain\", \"\", \"\"] == True]\n",
    "is_train = df[\"istrain\", \"\", \"\"].to_list()\n",
    "train_indices = [index for index, flag in enumerate(is_train) if flag]\n",
    "\n",
    "df_val = df[df[\"istrain\", \"\", \"\"] == False]\n",
    "is_val = [not flag for flag in is_train]\n",
    "val_indices = [index for index, flag in enumerate(is_val) if flag]\n",
    "\n",
    "# Drop flag column\n",
    "\n",
    "df = df.drop(columns=[\"istrain\"], axis=1, level=0)\n",
    "df.to_hdf(data_dir / \"CollectedData_scorer.h5\", key=\"df\", mode=\"w\")\n",
    "\n",
    "# Copy trains set images\n",
    "\n",
    "file_paths = df_train.index.to_list()\n",
    "dataset_dir = Path(\"../coco/train2017\")\n",
    "with open(\"files-to-copy_train.txt\", \"w\") as outfile:\n",
    "    outfile.writelines(map(lambda path: str(dataset_dir / os.path.basename(path)) + \"\\n\", file_paths))\n",
    "\n",
    "!cat files-to-copy_train.txt | xargs -I % cp % {data_dir}\n",
    "\n",
    "# Repeat for validation sets\n",
    "\n",
    "file_paths = df_val.index.to_list() # TODO: Change to df when still in test phase (!)\n",
    "dataset_dir = Path(\"../coco/val2017\")\n",
    "with open(\"files-to-copy_val.txt\", \"w\") as outfile:\n",
    "    outfile.writelines(map(lambda path: str(dataset_dir / os.path.basename(path)) + \"\\n\", file_paths))\n",
    "\n",
    "!cat files-to-copy_val.txt | xargs -I % cp % {data_dir}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd081d68",
   "metadata": {},
   "source": [
    "Assert COCO training data has been loaded into required folder. When run for the first time, this also plots the keypoint annotations with the frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3b5379f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "d3b5379f",
    "outputId": "13e5f9b4-ab8b-4c7d-b6cf-cbffb68ed826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by scorer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [00:00<00:00, 13.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dlc.check_labels(config_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1efeb7",
   "metadata": {
    "id": "5e1efeb7"
   },
   "source": [
    "Here I am unsure: Do I need to run create_training_dataset? I would like to keep the splits as defined by COCO, because this prevents bias introduction. However, as for data, this step will create a .mat file, which contains the\n",
    "address of the images as well as the target postures, and a .pickle file, which contains the meta\n",
    "information about the training dataset - DLC probably requires this.\n",
    "\n",
    "So the solution I think I will go with is to use create_training_dataset and create a training dataset with default settings, grab that .h5, and figure out the indices of the images I want in training/testing. Using my preprocessing routine, I merge the train/test DataFrames, sort them lexicographically by integer (as DLC does when splitting), and mark which images to be used for training. After doing that, I know which indices to enter here and I can use the DLC function.\n",
    "\n",
    "#### Think:\n",
    "Do we want shuffles? I can then create two model instances that have the identical training set, allowing me to assess the role of various parameters on the performance of DLC (each shuffle would include all of the same images, just allocated differently - unsure if this means just changing the order or also the set to which each is assigned...). Also, I am working with this multiple times on the same day, I might need to use shuffles because DLC might not overwrite certain files/folders.\n",
    "\n",
    "/!\\ After throwing out images with too few keypoints, does the split ratio still make sense?\n",
    "\n",
    "/!\\ Consider setting the augmenter type to the one used during pre-training (no information found in journal article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cdf843af",
   "metadata": {
    "id": "cdf843af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You passed a split with the following fraction: 80%\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.8, 1, (array([0, 1, 2, 3]), array([4])))]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlc.create_training_dataset(\n",
    "    config=config_path,\n",
    "    trainIndices=[train_indices,],\n",
    "    testIndices=[val_indices,],\n",
    "    net_type=\"resnet_50\", # set to the same neural network as pre-trained model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b2fb8e",
   "metadata": {
    "id": "62b2fb8e"
   },
   "source": [
    "Actual training can start now.\n",
    "\n",
    "Should I set `keepdeconvweights` to `False`? I think so. This means I won't update their weights during training and assumes that the pre-trained features are already relevant (learned meaningful features from the macaques) and can generalize well. (It would definitely be necessary if I used a different set or different names of bodyparts.)\n",
    "\n",
    "#### Think:\n",
    "\n",
    "/!\\ Do I have to set \"trainingsetindex\"? (Integer specifying which training set fraction to use. By default it is the first index value listed, note that Training Fraction is a list in config.yaml)\n",
    "\n",
    "/!\\ DLC apparently doesn't update the TrainingFraction in config.yaml automatically. Is that a problem?\n",
    "\n",
    "How can we optimize the model (or its parameters)? Is it through shuffling? Potentially check out `create_training_model_comparison`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c6454f7",
   "metadata": {
    "id": "c2dd4229"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mrp-scorer-2023-06-09/dlc-models/iteration-1/mrpJun9-trainset95shuffle1/train/pose_cfg.yaml\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m pose_config_path \u001b[38;5;241m=\u001b[39m Path(os\u001b[38;5;241m.\u001b[39mgetcwd()) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mrp-scorer-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoday\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/dlc-models/iteration-1/mrp\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoday\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;132;01m%e\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-trainset\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(config_file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrainingFraction\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mshuffle1/train/pose_cfg.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(pose_config_path)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m pose_config_path\u001b[38;5;241m.\u001b[39mis_file()\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# unsure if this is the right iteration value...\n",
    "pose_config_path = Path(os.getcwd()) / f\"/mrp-scorer-{today}/dlc-models/iteration-1/mrp{today.strftime('%b%e').replace(' ','')}-trainset{str(int(config_file['TrainingFraction'][0] * 100))}shuffle1/train/pose_cfg.yaml\"\n",
    "print(pose_config_path)\n",
    "assert pose_config_path.is_file()\n",
    "pose_config_file = dlc.auxiliaryfunctions.read_plainconfig(pose_config_path)\n",
    "\n",
    "# In pose_cfg.yaml of the latest iteration, change init_weights to the last snapshot of the pre-trained model\n",
    "init_weights_path = Path(os.getcwd()) / f\"/mrp-scorer-{today}/dlc-models/iteration-0/mrp{today.strftime('%b%e').replace(' ','')}-trainset{str(int(config_file['TrainingFraction'][0] * 100))}shuffle1/train/snapshot-1030000\"\n",
    "pose_config_file[\"init_weights\"] = str(init_weights_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2dd4229",
   "metadata": {
    "id": "c2dd4229"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dlc\u001b[38;5;241m.\u001b[39mtrain_network(\u001b[43mconfig_path\u001b[49m, keepdeconvweights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config_path' is not defined"
     ]
    }
   ],
   "source": [
    "dlc.train_network(\n",
    "    config_path,\n",
    "    keepdeconvweights=False,\n",
    ")\n",
    "# /!\\ before GPU access: set max_iters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718413b9",
   "metadata": {
    "id": "718413b9"
   },
   "source": [
    "==================================================================================================================\n",
    "\n",
    "Now, we can evaluate the performance using the mean average Euclidean error (MAE; which is proportional to the average root mean square error) between the manual labels and the ones predicted. Hopefully, DLC automatically uses the correct test split. Results are stored as .csv file in a subdirectory under evaluation-results, displayed for all pairs and only likely pairs (>p-cutoff). (This helps to exclude, for example, occluded body parts.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4222810",
   "metadata": {
    "id": "c4222810"
   },
   "outputs": [],
   "source": [
    "dlc.evaluate_network(config_path, plotting=True) # setting plotting to True plots all the testing and training frames with the manual and predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02560730",
   "metadata": {
    "id": "02560730"
   },
   "source": [
    "DLC offers much more: here goes the optional stuff included in demos I read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121cd022",
   "metadata": {
    "id": "121cd022"
   },
   "outputs": [],
   "source": [
    "# Optional (I guess?) Don't know if it works without the \"true\" videos\n",
    "dlc.analyze_videos(path_to_config, [video_path])\n",
    "\n",
    "# Optional (I guess?) Create labeled video, watch options\n",
    "dlc.create_labeled_video(path_to_config, [video_path])\n",
    "\n",
    "# Optional (I guess?) Plot trajectories of all body parts across entire video\n",
    "dlc.plot_trajectories(path_to_config, [video_path])\n",
    "\n",
    "# Optional: Extract outliers and refine labels\n",
    "dlc.extract_outlier_frames(path_to_config, [video_path])\n",
    "dlc.refine_labels(path_to_config)\n",
    "#(deeplabcut.label_frames(path_config_file), deeplabcut.check_labels(path_config_file))\n",
    "dlc.create_training_dataset(path_to_config) #?\n",
    "\n",
    "# => reiterate process, mind merge_datasets if labels refined!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "433bb754a9804b2082279408bcc0b475": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6eb4b916a5474378a25ed3fe14a6b7cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1f1df6732a343789fe6a99f3c8af4b7",
      "max": 182137107,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ae4402332ffe403b9255be9e0326b268",
      "value": 182137107
     }
    },
    "7375a8cf081949a696e0076c100c4afa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96d5d8708f6d495dbeea3790037c4afc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a48d9de30ddf459aa5336875598bbe29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4b51803fb314a82970dead9a0b39c9f",
      "placeholder": "​",
      "style": "IPY_MODEL_96d5d8708f6d495dbeea3790037c4afc",
      "value": "Downloading (…)full_resnet50.tar.gz: 100%"
     }
    },
    "ae4402332ffe403b9255be9e0326b268": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b4b51803fb314a82970dead9a0b39c9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6ca5ecece2443ddad8a8eab539ceef2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cbcd3ba6bed1420eb3d944b4e16fd2f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_433bb754a9804b2082279408bcc0b475",
      "placeholder": "​",
      "style": "IPY_MODEL_c6ca5ecece2443ddad8a8eab539ceef2",
      "value": " 182M/182M [00:02&lt;00:00, 71.4MB/s]"
     }
    },
    "d1f1df6732a343789fe6a99f3c8af4b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1eb9cf9735d486d9387cde84ab171c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a48d9de30ddf459aa5336875598bbe29",
       "IPY_MODEL_6eb4b916a5474378a25ed3fe14a6b7cf",
       "IPY_MODEL_cbcd3ba6bed1420eb3d944b4e16fd2f3"
      ],
      "layout": "IPY_MODEL_7375a8cf081949a696e0076c100c4afa"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
